{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2782634b-3c33-4ccc-8172-5b290c28574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7233b0ca-9d1d-4133-8769-3d9cd9866fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparams \n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "validation_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c4b4104-6e6d-46a3-b1ba-0b6ee2b5eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "256fe92f-ca80-4106-8676-b7de48b019dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\python\\datasets_storage'\n",
    "test_data = torchvision.datasets.CIFAR100(root=path,train=False,download=True, transform=transform)\n",
    "dataset_train = torchvision.datasets.CIFAR100(root=path,train=True,download=True, transform=transform)\n",
    "\n",
    "train_data,validation_data=torch.utils.data.random_split(dataset_train,[int((1-validation_ratio)*len(dataset_train)), int((validation_ratio)*len(dataset_train))])\n",
    "print(len(validation_data))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ac711f6-648c-4a85-9966-45f3ca80e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35607460-4344-4279-be1a-a9fd36ce2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_device():\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "def move_device(tensor,device):\n",
    "    if isinstance(tensor,(list,tuple)):    \n",
    "      return[move_device(element,device) for element in tensor]  \n",
    "    return tensor.to(device,non_blocking=True)\n",
    "class DeviceDataloader():\n",
    "    def __init__(self,dataloader,device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        # transfer ecach batch and return\n",
    "        for i in self.dataloader:\n",
    "           yield move_device(i, self.device)\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataloader)\n",
    "device = check_device()\n",
    "\n",
    "train_dl = DeviceDataloader(train_loader, device)\n",
    "test_dl = DeviceDataloader(test_loader, device)\n",
    "val_dl  = DeviceDataloader(val_loader, device)\n",
    "#len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6ac72ca-658e-4268-9098-4081aaa39bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_model(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (hidden_layer): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (output_layer): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(CNN_model,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(32), # out channels, helps normalize batches and imporves overall better performance\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.hidden_layer = nn.Linear(256 * 2 * 2, 512)\n",
    "        self.output_layer = nn.Linear(512, 100)\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.conv4(output)\n",
    "        #flattening \n",
    "        output = output.view(-1, 256 * 2 * 2)\n",
    "        # fully connected layers\n",
    "        output = self.hidden_layer(output)\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "model = CNN_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9eeb8c85-228f-4930-9e05-e2e3595089a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr= 3e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5d6c0ae-fb48-48a9-a793-3f5256ab9112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda if torch.cuda.is_available() else \"CUDA not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96a12572-66f4-48e3-81a7-54fd13358283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n"
     ]
    }
   ],
   "source": [
    "print('Starting...')\n",
    "epochs = 2\n",
    "model = model.to(device)\n",
    "def model_train(model, train_loader, criterion, optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx,(images,targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            images,targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item() ### compares predicted lables to true lables and returns True/False\n",
    "            batch_idx += 1\n",
    "        \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch\" {epoch + 1}/{epochs} | Loss:{running_loss} | '\n",
    "                      f'Loss: {running_loss / (batch_idx+1):.4f} | '\n",
    "                      f'Acc_train: {100.*correct/total:.2f}% | '\n",
    "                      f'Batch: {batch_idx / len(train_loader)}')\n",
    "def model_val(model, val_loader):\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, targets in val_loader:\n",
    "            with torch.no_grad():\n",
    "                images,targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "    \n",
    "                loss = criterion(outputs, targets)\n",
    "    \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                return val_loss/len(val_loader), 100.* correct/total\n",
    "        print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8065a7dd-4e89-47e9-b09c-e66801e1de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\" 1/2 | Loss:454.0982165336609 | Loss: 4.4960 | Acc_train: 2.55% | Batch: 0.16\n",
      "Epoch\" 1/2 | Loss:872.953848361969 | Loss: 4.3431 | Acc_train: 4.41% | Batch: 0.32\n",
      "Epoch\" 1/2 | Loss:1275.6716899871826 | Loss: 4.2381 | Acc_train: 5.66% | Batch: 0.48\n",
      "Epoch\" 1/2 | Loss:1666.998646736145 | Loss: 4.1571 | Acc_train: 6.83% | Batch: 0.64\n",
      "Epoch\" 1/2 | Loss:2047.979740858078 | Loss: 4.0878 | Acc_train: 7.74% | Batch: 0.8\n",
      "Epoch\" 1/2 | Loss:2421.242255926132 | Loss: 4.0287 | Acc_train: 8.58% | Batch: 0.96\n",
      "Epoch\" 2/2 | Loss:364.2016565799713 | Loss: 3.6060 | Acc_train: 13.88% | Batch: 0.16\n",
      "Epoch\" 2/2 | Loss:722.3185751438141 | Loss: 3.5936 | Acc_train: 14.62% | Batch: 0.32\n",
      "Epoch\" 2/2 | Loss:1073.6670396327972 | Loss: 3.5670 | Acc_train: 15.25% | Batch: 0.48\n",
      "Epoch\" 2/2 | Loss:1417.8010609149933 | Loss: 3.5357 | Acc_train: 15.82% | Batch: 0.64\n",
      "Epoch\" 2/2 | Loss:1761.9589140415192 | Loss: 3.5169 | Acc_train: 16.24% | Batch: 0.8\n",
      "Epoch\" 2/2 | Loss:2099.3325831890106 | Loss: 3.4931 | Acc_train: 16.79% | Batch: 0.96\n"
     ]
    }
   ],
   "source": [
    "model_train(model,train_loader, criterion, optimizer)\n",
    "val_loss, val_acc = model_val(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32a901e0-788e-42de-9bc0-c5a3d99005e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_loss: 0.0219, Val_acc: 17.1875%\n"
     ]
    }
   ],
   "source": [
    "print(f'Val_loss: {val_loss:.4f}, Val_acc: {val_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034e87e-bce0-4335-b463-5433cad4f112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
